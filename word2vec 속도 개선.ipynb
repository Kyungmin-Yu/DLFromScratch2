{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b72c5a3",
   "metadata": {},
   "source": [
    "# word2vec 개선 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe6536",
   "metadata": {},
   "source": [
    "- CBOW모델은 단어 2개를 맥락으로 사용해 이를 바탕으로 하나의 단어를 추측함\n",
    "- 입력 측 가중치와의 행렬 곱으로 은닉층 계산\n",
    "- 출력 측 가중치 행렬 곱으로 점수 구함\n",
    "- 점수에 소프트맥스 함수 적용해 출현 확률 도출\n",
    "- 이 확률을 정답 레이블과 비교 (교차 엔트로피 오차 적용) 손실 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4e119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:31:49.489904Z",
     "start_time": "2023-07-09T13:31:49.469119Z"
    }
   },
   "source": [
    "병목을 초래하는 요소\n",
    "- 입력층의 원핫 표현과 가중치 행렬 W_in 곱 계산\n",
    "    -> embedding 계층 도입으로 해결\n",
    "- 은닉층과 가중치 행렬 W_out의 곱과 softmax 계층 계산\n",
    "    -> negative sampling 도입으로 해결 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c278c5",
   "metadata": {},
   "source": [
    "## Embedding 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70c69a",
   "metadata": {},
   "source": [
    "- 실질적으로는 행렬의 특정 행을 추출하는 연산만 수행됨\n",
    "- 따라서 원핫 변환과 matmul 계층의 행렬 곱 계산을 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f174c3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:34:35.669911Z",
     "start_time": "2023-07-09T13:34:35.631975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14],\n",
       "       [15, 16, 17],\n",
       "       [18, 19, 20]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "W = np.arange(21).reshape(7,3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6839e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:35:18.733512Z",
     "start_time": "2023-07-09T13:35:18.724359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 0,  1,  2],\n",
       "       [ 9, 10, 11],\n",
       "       [ 0,  1,  2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W로 부터 원하는 여러 행은 다음과 같이 추출 가능함\n",
    "idx = np.array([1,0,3,0])\n",
    "W[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98dcff53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:36:19.241812Z",
     "start_time": "2023-07-09T13:36:19.219094Z"
    }
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1d27e",
   "metadata": {},
   "source": [
    "- 순전파: 가중치 W의 특정 행 추출\n",
    "- 역전파: 앞 층으로 부터 전해진 기울기를 그대로 흘려 보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d164f0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:43:53.312755Z",
     "start_time": "2023-07-09T13:43:53.297691Z"
    }
   },
   "outputs": [],
   "source": [
    "def backward(self, dout):\n",
    "    dW, = self.grads\n",
    "    dW[...] = 0\n",
    "    dW[self.idx] = dout\n",
    "    return None\n",
    "# 해당 방식을 사용하면 idx 원소가 중복될 때 중복 할당되며 덮어씌워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18346b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T13:44:51.857183Z",
     "start_time": "2023-07-09T13:44:51.839547Z"
    }
   },
   "outputs": [],
   "source": [
    "# 할당이 아닌 더하기를 통해 해결\n",
    "def backward(self, dout):\n",
    "    dW, = self.grads\n",
    "    dW[...] = 0\n",
    "    \n",
    "    for i, word_id in enumerate(self.idx):\n",
    "        dW[word_id] +=dout[i]\n",
    "    return None\n",
    "\n",
    "# W와 같은 크기의 dW 행렬을 만들어 둘 필요는 없지만 이렇게 한 이유는 갱신용 클래스 Optimizer와 조합해 사용하기 위해서임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b1630",
   "metadata": {},
   "source": [
    "# word2vec 개선 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60612b27",
   "metadata": {},
   "source": [
    "## 은닉층 이후 계산의 문제점\n",
    "- 은닉층의 뉴런과 가중치 행렬 (W_out)의 곱\n",
    "- softmax 계층 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac98b8b",
   "metadata": {},
   "source": [
    "## 다중 분류에서 이진 분류로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cdd221",
   "metadata": {},
   "source": [
    "- Yes/No로 답변 가능한 질문으로 변환 필요\n",
    "    -> 맥락이 you와 goodbye 일 때, 타깃 단어는 say입니까? 라는 질문에 답하는 신경망을 고안해야 함\n",
    "- 이전의 출력층에서는 모든 단어를 대상으로 계산을 수행했다면, 여기서는 say 라는 단어 하나에 주목해 그 점수만을 계산하는 차이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aee294",
   "metadata": {},
   "source": [
    "## 시그모이드 함수와 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c8cf9",
   "metadata": {},
   "source": [
    "- 이진 분류: 점수에 시그모이드 함수를 적용해 확률로 변환\n",
    "- 손실함수: 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b1e91",
   "metadata": {},
   "source": [
    "## 다중 분류에서 이진 분류로(구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eeaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis = 1)\n",
    "        \n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0], 1)\n",
    "        \n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93147e88",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c98fd8",
   "metadata": {},
   "source": [
    "- 긍정적인 예에 대해서는 sigmoid 계층의 출력을 1에 가깝게 만들고, 부정적 예에 대해서는 sigmoid 계층의 출력을 0에 가깝게 만들어야 함\n",
    "- 모든 부정적인 예를 대상으로 이진분류를 학습: 어휘 수가 늘어나면 감닫ㅇ 불가\n",
    "- 부정적인 예를 몇개 선택하는 네거티브 샘플링 도입\n",
    "- 네거티브 샘플링 기법은 긍정, 부정 예의 손실을 더한 값을 최종 손실로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366120a",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링의 샘플링 기법\n",
    "- 말뭉치의 통계 데이터를 기초로 샘플링\n",
    "- 말뭉치에서 자주 등장하는 단어를 많이 추출하고, 드물게 등장하는 단어를 적게 추출함\n",
    "- 희소한 단어는 선택되기 어려움\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac27992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:40:19.878134Z",
     "start_time": "2023-07-13T14:40:19.853153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0에서 9까지의 숫자 중 하나를 무작위 샘플링\n",
    "np.random.choice(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b04c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:50:56.456533Z",
     "start_time": "2023-07-13T14:50:56.434586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['you', 'say', 'goodbye', 'I', 'hello', '.']\n",
    "np.random.choice(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5131b34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:51:24.485395Z",
     "start_time": "2023-07-13T14:51:24.466446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', '.', '.', 'say', 'hello'], dtype='<U7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개 샘플링 (중복 있음)\n",
    "np.random.choice(words, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da8a06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:51:56.194783Z",
     "start_time": "2023-07-13T14:51:56.171850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['say', '.', 'I', 'goodbye', 'hello'], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개 샘플링 (중복 없음)\n",
    "np.random.choice(words, size=5, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae9aef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:52:23.716170Z",
     "start_time": "2023-07-13T14:52:23.696224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률분포에 따라 샘플링\n",
    "p = [0.5, 0.1, 0.05, 0.2, 0.05, 0.1]\n",
    "np.random.choice(words, p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c100a3",
   "metadata": {},
   "source": [
    "- 확률에 0.75 제곱을 하고, 변형된 확률 분포의 합으로 나누어 사용\n",
    "- 이는 출현 확률이 낮은 단어를 버리지 않기 위함임\n",
    "- 0.75 제곱을 통해 원래 확률 낮은 단어의 확률을 살짝 올릴 수 있음\n",
    "- 0.75에 이론적 의미는 없으므로 다른 값 사용해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e02236a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:55:54.180496Z",
     "start_time": "2023-07-13T14:55:54.166533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64196878 0.33150408 0.02652714]\n"
     ]
    }
   ],
   "source": [
    "p = [0.7, 0.29, 0.01]\n",
    "new_p = np.power(p, 0.75)\n",
    "new_p /= np.sum(new_p)\n",
    "print(new_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0632283",
   "metadata": {},
   "source": [
    "Unigramsampler class의 인수\n",
    "- corpus: id 목록\n",
    "- power: 제곱할 값\n",
    "- sample_size: 네거티브 샘플링 수행 횟수\n",
    "\n",
    "Unigramsampler class의 메서드\n",
    "- get_negative_sample: target 인수로 지정한 단어를 긍정적 예로 해석하고, 그 외 단어 ID를 샘플링 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e86c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:02:31.175252Z",
     "start_time": "2023-07-13T15:02:31.089483Z"
    }
   },
   "outputs": [],
   "source": [
    "from negative_sampling_layer import UnigramSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823d6cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:02:31.896218Z",
     "start_time": "2023-07-13T15:02:31.869289Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [1 2]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpus = np.array([0,1,2,3,4,1,2,3])\n",
    "power = 0.75\n",
    "sample_size = 2\n",
    "\n",
    "sampler = UnigramSampler(corpus, power, sample_size)\n",
    "target = np.array([1,3,0])\n",
    "negative_sample = sampler.get_negative_sample(target)\n",
    "print(negative_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984edfa",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3300729a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:06:56.531463Z",
     "start_time": "2023-07-13T15:06:56.504537Z"
    }
   },
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power = 0.75, sample_size = 5):\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size + 1)] # +1 for positive\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
    "        self.params , self.grads = [], []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target)\n",
    "        \n",
    "        # 긍정적 예 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = np.ones(batch_size, dtype=np.int32)\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "        \n",
    "        # 부정적 예 순전파\n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, i]  # embed_dot에 해당하는 타겟이라는 의미인 듯\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layers[1 + i].forward(score, negative_label)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "        \n",
    "        return dh       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa9888",
   "metadata": {},
   "source": [
    "# 개선판 word2vec 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509cb62",
   "metadata": {},
   "source": [
    "## CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cbeb6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:19:39.993285Z",
     "start_time": "2023-07-14T16:19:39.907580Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from common.layers import Embedding\n",
    "from negative_sampling_layer import NegativeSamplingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f79b437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:19:55.632495Z",
     "start_time": "2023-07-14T16:19:55.606796Z"
    }
   },
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        \n",
    "        # 레이어 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "        \n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs1 = W_in\n",
    "        self.word_vecs2 = W_out\n",
    "        \n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)  # average\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab07d1",
   "metadata": {},
   "source": [
    "## CBOW 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db93aaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:24:44.534056Z",
     "start_time": "2023-07-14T16:23:21.589707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23100a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:28:53.344928Z",
     "start_time": "2023-07-14T16:28:53.326977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ykm25\\\\DLFromScratch2\\\\Chap04-Word2Vec_Improved'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a0a672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:36:47.624255Z",
     "start_time": "2023-07-14T16:36:18.817654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e65efb94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:37:22.791405Z",
     "start_time": "2023-07-14T16:37:22.774394Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('C:\\\\Users\\\\ykm25\\\\DLFromScratch2\\\\')\n",
    "import numpy as np\n",
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ===============================================\n",
    "# config.GPU = True\n",
    "# ===============================================\n",
    "import pickle\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from cbow import CBOW\n",
    "from skip_gram import SkipGram\n",
    "from common.util import create_contexts_target, to_cpu, to_gpu\n",
    "from datasets import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e5845cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:13.923374Z",
     "start_time": "2023-07-14T16:52:07.409552Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 1\n",
    "\n",
    "# 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "# if config.GPU:\n",
    "#     contexts, target = to_gpu(contexts), to_gpu(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "304065b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:19.570338Z",
     "start_time": "2023-07-14T16:52:13.992957Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 등 생성\n",
    "model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4eba60",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-14T16:52:08.701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 9295 | 시간 0[s] | 손실 41.59\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size, eval_interval=2000)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c2db9",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e71190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:04.724488Z",
     "start_time": "2023-07-14T16:40:00.703Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pickle\n",
    "from common.util import most_similar, analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0cebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:04.733464Z",
     "start_time": "2023-07-14T16:40:01.035Z"
    }
   },
   "outputs": [],
   "source": [
    "pkl_file = './cbow_params.pkl'\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c334e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:04.747428Z",
     "start_time": "2023-07-14T16:40:01.427Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vecs = params['word_vecs']\n",
    "word_to_id = params['word_to_id']\n",
    "id_to_word = params['id_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf05d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:04.765379Z",
     "start_time": "2023-07-14T16:40:01.882Z"
    }
   },
   "outputs": [],
   "source": [
    "# 가장 비슷한(most similar) 단어 뽑기\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e14e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T16:52:04.789313Z",
     "start_time": "2023-07-14T16:40:02.283Z"
    }
   },
   "outputs": [],
   "source": [
    "# 유추(analogy) 작업\n",
    "print('-'*50)\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
